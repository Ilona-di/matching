Целью данного проекта было разработать алгоритм, который на основании обучающих данных из таблицы base сможет для каждой позиции из списка запросов находить наиболее близкий объект. Разрабатывать алгоритм на тренировочной выборке train, в качестве правильных ответов использовать значения из колонки "Target". Протестировать алгоритм на валидационной выборке valid, правильные ответы приведены в таблице valid_answer, в качестве метрики использовать Accuracy@5, то есть частоту попадания правильного ответа в 5-ку самых близких объектов, подобранных алгоритмом.

В данном проекте мы использовали приближённый поиск по ближайшим соседям и библиотеку FAISS для создания алгоритма по определению наиболее похожих объектов. Для оценки эффективности алгоритма использовалась метрика Accuracy@5, которая показывает, насколько часто максимально похожий объект находится в пяти самых похожих по результатам работы алгоритма. 

Мы подобрали оптимальное количество ячеек, на которые разбивается база данных и количество соседних ячеек, по которым происходит поиск похожих объектов.

Значение accuracy@5 с изначальным кодом (количество ячеек n_cells=1) было равно 13.8. С увеличением cells до 10 метрика упала до 12, но и код стал выполняться быстрее. С увеличением cells до 100 метрика ещё упала - 7.7, а код стал выполняется пару минут. Добавили nprobes = 10 - и метрика увеличилась до 13.65 - почти как в начале, однако, код выполняется намного быстрее (в самом начале было минут 40, а теперь 5 минут). Когда вместо 5-ти ближайших соседей ищем 50 - acuuracy увеличивается до 16.544, а на 100 - до 17.426, среди 200 соседей - 18.41. 
Далее смотрела accuracy@5 как целевую метрику, а также accuracy@200 (200 наиболее похожих позиций) - чтобы оценить, можно ли брать результат для дальнейшей оптимизации каким-либо методом ML, так как, чтобы перейти к дальнейшему отбору, нужно, чтобы правильный ответ был во всех списках, полученных на этапе faiss.

После введения предобработки данных (удаление или модификация данных в двух столбцах без нормального распределения) accuracy@5 стала равна 20.295. После кодирования столбцов Ordinal encoder-ом accuracy@5 стала 26.26. После масштабирования accuracy@5 67.598, при этом accuracy@200 становится 79.881. Попробовала удалить вообще все ненормально распределённые столбцы - получила accuracy@5 70.478, то етсь выше, чем раньше. Accuracy@200 80.682.
Если из столбцов, где нет нормального распределения, удалить те, в которых невозможно увидеть закономерность распределения значений (33, 59, 65), а у остальных (6, 21, 25, 44, 70) данные сгруппировать и закодировать Ordinal ENcoder-ом - получаем accuracy@5 69.868, accuracy@200 80.72. Эти значения не сильно отличаются от ситуации, когда мы всё просто удаляли.

К сожалению, не успеваю оптимизировать поиск при помощи моделей машинного обучения. Написала цикл, который создаёт матрицу для дальнейшего анализа при помощи catboost, но он работает очень медленно, даже при небольшом количестве векторов.

Провела валидацию, используя только приближённый поиск ближайших соседей с помощью FAISS. На валидационной выборке получили accuracy@5 69.676 - почти точно такой же, как на тренировочной.
